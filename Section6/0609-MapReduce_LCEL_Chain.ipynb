{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMapReduce LCEL Chain.\\n\\ntodos\\n* list of docs\\n    # 문서를 얻어서..\\n* for doc in list of docs | prompt | llm\\n    # 각각의 문서를 llm 으로 필요한 정보를 얻는다.\\n* for responsein list of llms response | put them all together\\n    # 각각의 문서 요약본을 하나의 문서로 정리.\\n* final doc | promt | llm\\n    # 요약 문서를 llm 으로 필요한 정보를 정리한다.\\n* chain.invoke\\n\\nnew\\nRunnableRambda\\n\\nexecute and after langchain.smith view.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "MapReduce LCEL Chain.\n",
    "\n",
    "todos\n",
    "* list of docs\n",
    "    # 문서를 얻어서..\n",
    "* for doc in list of docs | prompt | llm\n",
    "    # 각각의 문서를 llm 으로 필요한 정보를 얻는다.\n",
    "* for responsein list of llms response | put them all together\n",
    "    # 각각의 문서 요약본을 하나의 문서로 정리.\n",
    "* final doc | promt | llm\n",
    "    # 요약 문서를 llm 으로 필요한 정보를 정리한다.\n",
    "* chain.invoke\n",
    "\n",
    "new\n",
    "RunnableRambda\n",
    "\n",
    "map_reduce2 -> map_reduce 로 바꾸는 연습.\n",
    "\n",
    "execute and after langchain.smith view.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Victory Mansions is an old, dilapidated building with constant maintenance issues. The flats were built around 1930 and are falling apart, with flaking plaster, burst pipes, leaky roofs, and an unreliable heating system. Repairs are delayed by remote committees, making it difficult to fix even minor issues. The Parsons' flat within Victory Mansions is described as larger than Winston's but has a dingy, battered appearance. The walls are adorned with games equipment, dirty dishes, Youth League and Spies banners, and a poster of Big Brother. The building has a common smell of boiled cabbage mixed with sweat. Despite its poor condition, Victory Mansions offers a view of all four Ministries, including the Ministry of Truth, although it is dwarfed by the surrounding architecture.\" 승리 아파트는 오래되고 낡은 건물로, 지속적인 유지보수 문제가 있다. 이 아파트는 1930년대에 지어졌으며 벽이 벗겨지고 파이프가 터지며 지붕이 새고 난방 시스템이 불안정하다. 수리는 원격 위원회에 의해 지연되어 작은 문제조차 해결하기 어렵다. 파슨스 가족의 아파트는 윈스턴의 것보다 크지만 험한 외관을 가지고 있다. 벽에는 게임 장비, 더러운 그릇, 청소년 연맹과 첩보원 휘장, 그리고 빅 브라더 포스터가 걸려있다. 건물 안은 삶은 양배추와 땀의 냄새가 섞인다. 상태가 좋지 않지만, 승리 아파트는 진실부를 포함한 네 개의 부처를 볼 수 있는 전망을 제공한다. 그러나 주변 건물에 가려져 있다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "#    model_name=\"gpt-4\",\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\") # gitignore 추가.\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.docx\")\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cache_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "# vectorstore = Chroma.from_documents(docs, cache_embeddings)\n",
    "vectorstore = FAISS.from_documents(docs, cache_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "        Use the following portion of a long document to see if any of the text is relevant to answer the question. Return any relevant text verbatim. If there is no relevant text, return : ''\n",
    "        -------\n",
    "        {context}\n",
    "     \"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "def map_reduce2(inputs):\n",
    "    documents = inputs['documents']\n",
    "    question = inputs['question']\n",
    "    results = []\n",
    "\n",
    "    for document in documents:\n",
    "        results.append(map_doc_chain.invoke({\n",
    "            \"context\": document.page_content,\n",
    "            \"question\": question,\n",
    "        }).content)\n",
    "\n",
    "    results = \"\\n\\n\".join(results)\n",
    "    return results\n",
    "\n",
    "def map_reduce(inputs):\n",
    "    documents = inputs['documents']\n",
    "    question = inputs['question']\n",
    "    return \"\\n\\n\".join(\n",
    "        map_doc_chain.invoke({\n",
    "            \"context\": doc,\n",
    "            \"question\": question,\n",
    "        }).content for doc in documents\n",
    "    )\n",
    "\n",
    "\n",
    "map_chain = {\n",
    "    \"documents\": retriever,\n",
    "    \"question\": RunnablePassthrough()\n",
    "} | RunnableLambda(map_reduce)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "     Given the following extracted parts of a long document and a question, create a final answer. \n",
    "     If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "     ------\n",
    "     {context}\n",
    "     \"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 검색 방법 설정.\n",
    "chain = {\"context\": map_chain, \"question\": RunnablePassthrough()} | prompt | llm\n",
    "\n",
    "chain_result = chain.invoke(\"Describe Victory Mansions.\")\n",
    "\n",
    "# chain_result\n",
    "\n",
    "ko_result = llm.predict(chain_result.content + \"\\n\\n한글로 번역해줘.\"\"\")\n",
    "\n",
    "print(chain_result, ko_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
